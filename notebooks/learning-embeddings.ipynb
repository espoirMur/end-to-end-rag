{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will be learning sentences embedding from our pubmed dataset. After learning the embedding we will save those embedding for paragraphs in a Postgres database. We will later use that database to query our question to find relevant paragraphs related to the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"pubmed_qa\"\n",
    "columns_to_use = ['pubid', 'question', 'context', 'long_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset = load_dataset(dataset_id,  \"pqa_unlabeled\")\n",
    "labeled_dataset = load_dataset(dataset_id,  \"pqa_labeled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_context(examples):\n",
    "    \"\"\"\n",
    "    Each column in the datase \n",
    "\n",
    "    Args:\n",
    "        context (dict): _description_\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "    all_contexts = examples.get(\"context\")\n",
    "    for context_dict in all_contexts:\n",
    "        contexts.extend(context_dict.get(\"contexts\"))\n",
    "    return {\"context\": contexts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pubid', 'question', 'context', 'long_answer'],\n",
       "        num_rows: 61249\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61249, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_dataset[\"train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_context_dataset =  unlabeled_dataset['train'].map(explode_context,\n",
    "     remove_columns=['question', 'long_answer', \"context\", \"pubid\"], \n",
    "     batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_context_dataset = labeled_dataset[\"train\"].map(explode_context, remove_columns=[\n",
    "                                              'question', 'long_answer', \"context\", \"pubid\", \"final_decision\"], batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dataset = concatenate_datasets([unlabeled_context_dataset, labeled_context_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check one split of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the context as data dataset, we can now save them in the database by using encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created our dataset, let us try to learn embedding of the first two sentences and check if the embedding model work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the embedding model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the sentence transformer model to learn the word embeddings of our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/esp.py/.cache/torch/sentence_transformers/michiyasunaga_BioLinkBERT-large. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 512\n"
     ]
    }
   ],
   "source": [
    "embedding_model_name = 'michiyasunaga/BioLinkBERT-large'\n",
    "\n",
    "# Load the BERT model\n",
    "model = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "# Display the max_sequence_length of the model\n",
    "max_sequence_length = model.max_seq_length\n",
    "print(\"Max Sequence Length:\", max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our model have a max_sequence_length of 512, we need to split the context into chunks of 512 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(examples):\n",
    "    \"\"\"\n",
    "    take a batch of example compute the embeddings and save the subset of the embeddings\n",
    "    Add a new columns named embedding to the subsets of example and save the subset locally.\n",
    "    \"\"\"\n",
    "    examples[\"embedding\"] = model.encode(examples[\"context\"], show_progress_bar=True)\n",
    "    examples.save_to_disk(\"embeddings_pubmed_qa\")\n",
    "    return examples  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_embeddings = context_dataset.map(extract_embeddings, batched=True, batch_size=16)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.get(\"HF_DATASETS_CACHE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code need to be fun from a GPU, need to find a way to connect to collab gpu local.\n",
    "\n",
    "This will be a fun for another day."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
