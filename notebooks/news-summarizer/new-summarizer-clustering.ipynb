{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e5f93-6606-489f-9464-87a28e83013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad95e2c-cebb-4965-9062-4d7de97328a0",
   "metadata": {},
   "source": [
    "### News Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a827ba-aa76-4a85-8098-dcbe67ba6410",
   "metadata": {},
   "source": [
    "In this post I will try to implement a news summarizer. \n",
    "\n",
    "Over the past month I have been collecting a lot of news article from major congolese website news webisite. I have those article saved in a postgres database. There are lot of fun stuff I can do with them. Among them there is a news summarizer. I want to analyze the daily news and find out what are the main news the website are talking about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c781d00f-afe4-4337-8c7a-c63e58a729c7",
   "metadata": {},
   "source": [
    "In this blog or series of post I will try to build that news summarizer. As of now I will structure it as follow. \n",
    "- Kmean clustering\n",
    "- Text Summarization with a Language Model\n",
    "- Deployment to Production and Building the UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f24ba8-f0d8-4e7a-8abe-d453bd503fba",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "We have the data save as text in a postgres database in this section we will query the database and load the data in a pandas dataframe for better analyzis. I have the code to connect and read from the postgres database embedded in modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c3fea-c548-4030-b857-7db9366e8caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a97c90-20f7-496b-be2e-b024cd270793",
   "metadata": {},
   "outputs": [],
   "source": [
    "%dotenv ./.env_prod -o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48bf007-62e8-4532-b4c4-31bbf16b81fa",
   "metadata": {},
   "source": [
    "The above line loads the database credentatials so that we can query the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c6ef8-470e-42f1-ab8d-d0b987abf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag.shared.database import execute_query, generate_database_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db7bed-b387-4d77-95e0-de2ad43145d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday_article_query = \"select content, title, posted_at,url from article where posted_at::date = CURRENT_DATE - interval '1 day'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1db0ab-e09f-4902-a754-878071f2316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684204f3-df24-49dc-b0df-3e315b416269",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_user = getenv('POSTGRES_USER')\n",
    "database_password = getenv('POSTGRES_PASSWORD')\n",
    "database_host = getenv('POSTGRES_HOST')\n",
    "database_port = getenv('POSTGRES_PORT')\n",
    "database_name = getenv('POSTGRES_DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee77219-df10-4432-a131-9d2ee19e8509",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_credentials = {\n",
    "    'user': database_user,\n",
    "    'password': database_password,\n",
    "    'host': database_host,\n",
    "    'port': database_port,\n",
    "    'database': database_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30c8ed-3e97-4f3c-9653-c696a18dfca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = generate_database_connection(database_crendentials=database_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e31740-d68a-45c6-9952-17dee6eb2278",
   "metadata": {},
   "source": [
    "With the credentials, the database connection, the query we can go ahead and query the database to retrieve the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251cc08d-4b84-457e-80e6-899b0df0d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results =execute_query(query=yesterday_article_query, database_connection=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a169c42-0cdc-43b9-82a7-fe4dcd9c051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b5fa4-a8c7-4f4c-93de-d753613d6387",
   "metadata": {},
   "source": [
    "We have our results in a list now we can put them in a dataframe from further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c4230a-79e2-4cf7-9a1d-a0f18b26991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a144f2b-14fd-4878-ac2f-ee1a4420f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df  = pd.DataFrame.from_records(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e321c50-045f-4a62-9d11-2207288dc677",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb08e3-023c-4665-9f0c-e943692faaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.columns =  [\"content\", \"title\", \"posted_at\", \"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11157fd-6a83-43db-a22f-3201f7135c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8b691e-2573-4ad2-8777-7555112abfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8265b63-f037-4fd2-980d-a6c185a10d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_directory = current_directory.joinpath(\"datasets\", \"today_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23171b-1972-44d5-9515-cc49448d286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_directory.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736a278-2358-46d8-8ea4-fbf5e25eb93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf80033-65fe-4289-b196-d8a1028b8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981211a5-e921-47dd-b7ff-3f9c596d83d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv(news_directory.joinpath(f\"{today}-news.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1cc3a-d06a-4b57-85a1-2e251e25e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4428962-3e2d-4011-b9d6-58b8467519e6",
   "metadata": {},
   "source": [
    "We have got our news dataset, we need to now do some preprocessing. The only preprocessing we will do will be to drop the duplicate in the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5088e74-ec03-49dc-a51e-99ea9c8a09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = news_df.drop_duplicates(subset=\"content\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3af6dc-1f5d-400d-8854-67b66926804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9569e5-8b8d-478c-9eaf-2ea62b472d72",
   "metadata": {},
   "source": [
    "Once we have dataset, we will need to use an embedding  model to learn representation of our dataset in an embedding space.\n",
    "\n",
    "We will be using the `dunzhang/stella_en_400M_v5`, it is a good model from huggingface despite his size it has a good score on different tasks  in both French and English on the MTEB leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5366596-166a-498b-83bc-3cddccd93d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_id = \"dunzhang/stella_en_400M_v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd91f7fd-6ee4-4d8d-ae5c-4e0863470404",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3d4ae-23d3-41bf-a71f-56e8706a50e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path  = current_directory.joinpath(embedding_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de2515-33c6-4c57-bf56-d6dd9edaa06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_path = current_directory.joinpath(\"models\", embedding_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed17da72-e126-4149-8a33-54a204280d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer_kwargs = {\"model_name_or_path\": embedding_model_path.__str__(),\n",
    "                      \"trust_remote_code\": True,\n",
    "                      \"device\": \"cpu\",\n",
    "                      \"config_kwargs\": {\"use_memory_efficient_attention\": False,\n",
    "                                        \"unpad_inputs\": False},\n",
    "                      \"cache_folder\": model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751f3124-8d8e-4317-8f8b-2c12e34bda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea05843a-b276-4573-98ed-b146c1886ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ac51a9-0c80-4896-bb73-622ced506b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "today_news_embeddings = sentence_transformer_model.encode(\n",
    "    news_df.content.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804887e-cd95-4b08-a461-73243a132899",
   "metadata": {},
   "outputs": [],
   "source": [
    "today_news_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b6afb4-991f-4088-ad41-da1e501deaf5",
   "metadata": {},
   "source": [
    "Now we have encoded our news in the embeddings, for each news we have an embedding vector of shape 1024. With those embedding we can now start clustering our news.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d6672-72ff-4bf2-a4ab-1198a47b8777",
   "metadata": {},
   "source": [
    "## Kmeans\n",
    "\n",
    "In this step, we will group our news embeddings in a cluster using the Kmean algorithm. The algorithm will try to group the news in clusters based on the similarity of their embedding vectors. After the clustering, we will have similar news grouped in similar clusters.\n",
    "\n",
    "### How do we pick the number of cluster?\n",
    "\n",
    "We will use the Shilouette score to get the best number of clusters.\n",
    "\n",
    ">The Silhouette Coefficient is a measure of how well samples are clustered with samples that are similar to themselves. Clustering models with a high Silhouette Coefficient are said to be dense, where samples in the same cluster are similar to each other, and well separated, where samples in different clusters are not very similar to each other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe97ac23-3bb4-43fa-85b6-33afdd0eda20",
   "metadata": {},
   "source": [
    "Given the a point $x_i$, and a cluster label $c_i$ to compute the shilloute score:\n",
    "- we compute the mean distance of the $x_i$ to all the point in cluster $c_i$, we call it $a_i$\n",
    "\n",
    "  ${\\displaystyle a_i={\\frac {1}{|C_{I}|-1}}\\sum _{j\\in C_{I},i\\neq j}d(i,j)}$\n",
    "\n",
    "  Note that we divide by don't want to include the current point when we are trying to compute the distance.\n",
    "  \n",
    "- $b_i$ is the a measure to how the point $x_i$ in cluster $c_i$ is disimilar to all other clusters $c_j$ with $c_j != c_i$.\n",
    "\n",
    "For each other clusters different $c_i$ we compute the mean distance between $x_i$ and all the points in the cluster.  Then we take the cluster that has the mean distance as the closest cluster to $x_i$.\n",
    "\n",
    "We define $b_i$ as:\n",
    "\n",
    "${\\displaystyle b_i=\\min _{J\\neq I}{\\frac {1}{|C_{J}|}}\\sum _{j\\in C_{J}}d(i,j)}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ee1a3-ebb1-496c-8e34-9f12adaa45f7",
   "metadata": {},
   "source": [
    "With those $a_i$, and $b_I$ we define the shiloute score of the point $x_i$ as $s_i$ to be\n",
    "\n",
    "${\\displaystyle s_i={\\frac {b_i-a_i}{\\max\\{a_i,b_i\\}}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a92f48-4995-4b9d-b835-2349a981e83e",
   "metadata": {},
   "source": [
    "This value varies between -1, and 1. 1 means our clusters are dense, and -1 means the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd3b3fa-dad4-4a07-9407-1f2b13a69fd8",
   "metadata": {},
   "source": [
    "Let us write a python function that will perform the clustering and return the k that gives us the best cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac7d2ae-5dc2-40e8-a1d2-94f9961f78b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c83533-7b2d-43a8-8d08-3b0ee95bf6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_estimator (X):\n",
    "    \"\"\" compute the k mean clustering, and return the best k that maximize the silhouette score\n",
    "    \"\"\"\n",
    "    k_mean_estimators = [\n",
    "        (f\"KMeans_{i}\", KMeans(n_clusters=i, random_state=42, max_iter=3000)) for i in range(3, X.shape[0])]\n",
    "    scores = []\n",
    "\n",
    "    best_estimator = None\n",
    "    best_metric = float(\"-inf\")\n",
    "    for estimator_name, estimator in k_mean_estimators :\n",
    "        estimator.fit(X)\n",
    "        labels = estimator.labels_\n",
    "        score = silhouette_score(\n",
    "            X, labels)\n",
    "        if score > best_metric :\n",
    "            best_metric = score\n",
    "            best_estimator = estimator\n",
    "        print(estimator_name, score)\n",
    "        scores.append(score)\n",
    "    return best_estimator, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bd9c9-b3ef-40b6-a5c3-412fb4c62db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator, scores = find_best_estimator(today_news_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338375f2-d425-4d9d-a46d-d6a1f255fd3c",
   "metadata": {},
   "source": [
    "In the above function we compute the shiloutte score for values for k ranging from 2 to the max number of datapoints in our dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1cbc7d-79a8-4327-9e0a-cadaae1de65b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Let plot now the similarity shilouette score and see how it grow with the number of cluster selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e21df-cfe4-4996-96c8-a90275fd7da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40dad8-fd90-43fd-b484-01597966e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = plt.figure(figsize=(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd789e45-e0cb-4089-95a0-a37afc9f5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = plt.figure(figsize=(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589eeacc-f9d2-4867-8fcd-89c096912657",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(3, today_news_embeddings.shape[0]), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a496d41-a338-4d86-9825-0544fe901869",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34857d0b-ef3e-4652-a81b-491ab2180986",
   "metadata": {},
   "source": [
    "We can see that the best estimator gave us the n cluster equal to 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64053a4-29f2-48ca-b8f1-9a9a59f1eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"k_means_labels\"] = best_estimator.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699dcbd6-c591-411b-98b9-32659bafec96",
   "metadata": {},
   "source": [
    "Now let us analyze the clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf776c-dbdd-404f-bd76-34b624b7bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_embeddings(dataframe, embeddings, index, label_column=\"labels\"):\n",
    "    \"\"\" take a matrix of embeddings and the labels.\n",
    "    for each label compute the cosine similarity of the document with that label.\n",
    "    \"\"\"\n",
    "    document_in_index = dataframe.query(f\"{label_column} == {index}\")\n",
    "    with pd.option_context('display.max_colwidth', None):\n",
    "        display(document_in_index.title)\n",
    "    document_index = document_in_index.index\n",
    "    vectors = embeddings[document_index]\n",
    "    return sentence_transformer_model.similarity(vectors,  vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f9f7a5-3a49-4524-8730-f7194c33c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_embeddings(news_df, today_news_embeddings,29, label_column=\"k_means_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1e4314-381f-4814-9847-1b661ce0476a",
   "metadata": {},
   "source": [
    "After the first look at the results we can see that the results are good, we have around 29 news cluster, for 72 news.\n",
    "Some news cluster have only one article which make sense, and othe have up to 6 articles. In the later analyzis we will only keep news articles that have more than one documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c0a9f1-cc94-4d91-8fa2-273d2ec1c866",
   "metadata": {},
   "source": [
    "Can we do better than that? Let now try hiearchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de87b1-afe2-4f67-b96b-6f018d38f7ca",
   "metadata": {},
   "source": [
    "## Hiearchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f000cb32-4a9b-442f-8c9e-9e44449a7c02",
   "metadata": {},
   "source": [
    "Hierarchical clustering is a clustering that uses an iterative approach to build the dendrogram.\n",
    "\n",
    "\n",
    "**How do we build a dendrogram?**\n",
    "\n",
    "Assuming we have `n` points that we would like to cluster, the algorithm starts with them and a similarity metric to use.\n",
    "In the first step, all the `n` points are grouped in a `n ` cluster, as each observation is treated as its cluster.\n",
    "Then, the next two similar clusters are fused into a cluster; at this point, we have `n-1` clusters.\n",
    "The algorithm will process iteratively  by fusing each cluster into each other until we have one cluster.  \n",
    "With one cluster we have our dendrogram complete.\n",
    "\n",
    "**How do we compute similarity between clusters?**\n",
    "\n",
    "We have the notion between similarity between two points, how do we compute the similartiy between a point and a cluster? or Between two clusters?\n",
    "The notion of similarity between two points can be extend to develop the notion of `linkage` which is how we evaluate the dissimiarity between two groups of observation or clusters.\n",
    "\n",
    "\n",
    "The linkage between two cluster is :\n",
    "\n",
    "All linkage metrics start by computing the pairwise  dissimilarity between the observations in cluster A and those in cluster B. \n",
    "\n",
    "Depending on how we will compute the overall dissimilarity from those pairwise dissimilarities, the linkage metric will be defined.\n",
    "\n",
    "The linkage is called:\n",
    "\n",
    "- __complete__: When overall dissimilarity is the largest of the pairwise dissimilarity.\n",
    "\n",
    "- __single__: When ovrrall dissimilarity is the smallest of the pairwise dissimilarity.\n",
    "\n",
    "- __average__: When overall dissimilarity is the average of the pairwise dissimilarity.\n",
    "\n",
    "As the result of the hierachical clustering is a tree, which can be visualized as a dendrogram.\n",
    "\n",
    "On the _y_ axis represent the distance cutt off use while computing the merging.\n",
    "On the _x_ axis represent the document which are group into cluster based on th colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e79d1c-b8e8-4674-b473-5351198aa30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a7622-a14c-4ce5-8b39-8e5a3597fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Linkage\n",
    "plt.figure(figsize = (20,10))\n",
    "mergings = linkage(today_news_embeddings,\n",
    "                   method='complete', metric='cosine')\n",
    "dendrogram(mergings)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1dfae-8398-4376-b6d6-dc0a6a74173f",
   "metadata": {},
   "source": [
    "The linkage method from scipy will make a hierachical clustering using the cosine similarity as the metrics for our embedding.\n",
    "On the above plot, the x axis represent the document which are group into cluster based on th colour, the y axis represent the distance cutt off use while computing the merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220ec26-a2ff-40e8-a32b-811340f664c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b36d48-9105-44f0-831a-424bbcce9b89",
   "metadata": {},
   "source": [
    "from the linkage matrix we can return the label using a metric cutt off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ddfcf3-f1e7-473c-970e-bf5f177db94e",
   "metadata": {},
   "source": [
    "How do we select the best metric cut-offm to use for the clustering?\n",
    "We will use the Shilouette score and the do the same approach we used with the kmean. We will select the metric that gives us a high silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e2aaa-ce59-43d2-9bc7-270e30ba42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_distance(X, merging):\n",
    "    \"\"\" start with the document embedding x, and the hierachical clustering, find the k that maximize the shilouette score\"\"\"\n",
    "    max_shilouette = float(\"-inf\")\n",
    "    return_labels = np.zeros(X.shape[0])\n",
    "    scores = []\n",
    "    number_of_clusters = []\n",
    "    best_k = 0\n",
    "    for k in np.arange(0.2, 0.7, 0.01):\n",
    "        labels = fcluster(merging, k, criterion=\"distance\")\n",
    "        score = silhouette_score(\n",
    "            X, labels\n",
    "        )\n",
    "        scores.append(score)\n",
    "        n_clusters = np.unique(labels).shape[0]\n",
    "        number_of_clusters.append(n_clusters)\n",
    "        if score > max_shilouette:\n",
    "            max_shilouette = score\n",
    "            return_labels = labels\n",
    "            best_k = k\n",
    "    return scores, return_labels, number_of_clusters, best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f77885-f273-4908-8794-8782eabdc475",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, label_hierarchical, number_of_clusters, best_k =  select_best_distance(today_news_embeddings, mergings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db06ed2-7550-4517-bef2-4f93ae4b4c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(0.2, 0.7, 0.01), scores)\n",
    "ax.set_xlabel(\"Distance metric\")\n",
    "ax.set_ylabel(\"silhouette score\")\n",
    "ax.set_title(\"silhouette score vs distance metric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb55eab-4e0e-4062-ab76-0e95c876542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label_hierarchical).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a74677-6270-4b2c-86ef-a89eeaaf10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f3a8c-1e73-4898-a37c-eecd5062f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735bc649-85e1-4df2-ade7-6a54ab8d282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(0.2, 0.7, 0.01), number_of_clusters)\n",
    "ax.set_xlabel(\"Distance metric\")\n",
    "ax.set_ylabel(\"silhouette score\")\n",
    "ax.set_title(\"distance vs number of clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb682fb-77dd-40b6-9e9d-6bb3f64afeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"label_hierachical\"] = label_hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327419a3-4025-4102-a929-924b3ee120ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.query(f\"label_hierachical == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cde67-7aef-433b-823e-506439300a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_embeddings(news_df, today_news_embeddings, 4, \"label_hierachical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb946ea-d769-4931-a061-d3aa2d5c27f7",
   "metadata": {},
   "source": [
    "Once i have got the best labeling, i can go ahead and select the most important cluster. \n",
    "\n",
    "This will be all the cluster with more than 1 document, the rest of the document will be considered as noise. Each cluster with one document will be considered as noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c22c8-37a1-4a22-bb2b-06d08b7e576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_counts = news_df.label_hierachical.value_counts()\n",
    "labels_with_more_than_one = cluster_counts[cluster_counts > 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff8db6-2aa8-41c9-a1f4-05c0ab031ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_news_df = news_df.loc[news_df.label_hierachical.isin(labels_with_more_than_one)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aba9fd-992a-46a2-9e33-61bacc2b8e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_news_df.to_csv(news_directory.joinpath(f\"{today}-important-news-clusters.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba61bc",
   "metadata": {},
   "source": [
    "At this point we have a notebook with the clustering results and those results are saved back in the folder. The next step will be to build an news cluster component that will be use in a downstream application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738db661-02d5-41fb-8969-3d8660db9664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
