{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esp.py/Projects/Personal/end-to-end-rag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path.cwd().joinpath(\"datasets\", \"embeddings_pubmed_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_dataset_with_embeddings = load_from_disk(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'context': Value(dtype='string', id=None), 'embedding': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=None, dataset_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_dataset_with_embeddings.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "database_user = getenv('POSTGRES_USER')\n",
    "database_password = getenv('POSTGRES_PASSWORD')\n",
    "database_host = getenv('POSTGRES_HOST')\n",
    "database_port = getenv('POSTGRES_PORT')\n",
    "database_name = getenv('POSTGRES_DB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2 import connect\n",
    "from pgvector.psycopg2 import register_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_connection = connect(\n",
    "    user=database_user,\n",
    "    password=database_password,\n",
    "    host=database_host,\n",
    "    port=database_port,\n",
    "    database=database_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_connection.set_session(autocommit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = database_connection.cursor()\n",
    "cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_vector(database_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"DROP TABLE IF EXISTS pubmed_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_creation_string =\"\"\"\n",
    "    CREATE TABLE pubmed_qa (id bigserial PRIMARY KEY,context TEXT, context_vector VECTOR(1024)\n",
    "    );\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    CREATE TABLE pubmed_qa (id bigserial PRIMARY KEY,context TEXT, context_vector VECTOR(1024)\\n    );'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_creation_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(database_creation_string)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our database connection, our dataset with embedding, let now insert the embedding and then text into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'embedding'],\n",
       "    num_rows: 206613\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_dataset_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg2.extras import execute_values      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'embedding'],\n",
       "    num_rows: 206613\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_dataset_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_batch_to_database(batch):\n",
    "    \"\"\"insert batch into database\n",
    "\n",
    "    Args:\n",
    "        batch (_type_): _description_\n",
    "    \"\"\"\n",
    "    embeddings = batch[\"embedding\"]\n",
    "    contexts = batch[\"context\"]\n",
    "    execute_values(\n",
    "    cur=cursor, sql=\"INSERT INTO pubmed_qa (context, context_vector) VALUES %s\",\n",
    "    argslist=zip(contexts, embeddings)\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function save_batch_to_database at 0x103e9b2e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 206613/206613 [07:05<00:00, 485.73 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'embedding'],\n",
       "    num_rows: 206613\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_dataset_with_embeddings.map(save_batch_to_database, batched=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have the embedding saved in the postgres, the next step will be to build the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_connection.close()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Part\n",
    "\n",
    "With our vector and context saved in the database we will move to the next step of our RAG application, the text retrieval.\n",
    "We will use the questions embeddings, and query the postgres database to find the cosine similarity with the context embeddings, and then return the top 5 context related to the question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esp.py/Projects/Personal/end-to-end-rag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query: str, embedding_model: SentenceTransformer, k: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Preform semantic search on the database.\n",
    "    Given the query, return the top k relevant documents from the database.\n",
    "\n",
    "    Args:\n",
    "        query (str): _description_\n",
    "        embedding_model (SentenceTransformer): _description_\n",
    "        k (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    embedding = np.array(embedding_model.encode(query))\n",
    "    with connect(\n",
    "        user=database_user,\n",
    "        password=database_password,\n",
    "        host=database_host,\n",
    "        port=database_port,\n",
    "        database=database_name\n",
    "    ) as conn:\n",
    "        register_vector(conn)\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                f\"SELECT context, context_vector FROM pubmed_qa ORDER BY context_vector <=> %s LIMIT %s\", (embedding, k),)\n",
    "            rows = cur.fetchall()\n",
    "            semantic_context = [\n",
    "                {\"text\": row[0], \"source\": row[1][:10]} for row in rows]\n",
    "    return semantic_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now download the question dataset and perform the query again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"pubmed_qa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset = load_dataset(dataset_id,  \"pqa_unlabeled\")\n",
    "labeled_dataset = load_dataset(dataset_id,  \"pqa_labeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pubid', 'question', 'context', 'long_answer'],\n",
       "        num_rows: 61249\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question = labeled_dataset[\"train\"][0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = 'michiyasunaga/BioLinkBERT-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/esp.py/.cache/torch/sentence_transformers/michiyasunaga_BioLinkBERT-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do mitochondria play a role in remodelling lace plant leaves during programmed cell death?'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contexts': ['Programmed cell death (PCD) is the regulated death of cells within an organism. The lace plant (Aponogeton madagascariensis) produces perforations in its leaves through PCD. The leaves of the plant consist of a latticework of longitudinal and transverse veins enclosing areoles. PCD occurs in the cells at the center of these areoles and progresses outwards, stopping approximately five cells from the vasculature. The role of mitochondria during PCD has been recognized in animals; however, it has been less studied during PCD in plants.',\n",
       "  'The following paper elucidates the role of mitochondrial dynamics during developmentally regulated PCD in vivo in A. madagascariensis. A single areole within a window stage leaf (PCD is occurring) was divided into three areas based on the progression of PCD; cells that will not undergo PCD (NPCD), cells in early stages of PCD (EPCD), and cells in late stages of PCD (LPCD). Window stage leaves were stained with the mitochondrial dye MitoTracker Red CMXRos and examined. Mitochondrial dynamics were delineated into four categories (M1-M4) based on characteristics including distribution, motility, and membrane potential (ΔΨm). A TUNEL assay showed fragmented nDNA in a gradient over these mitochondrial stages. Chloroplasts and transvacuolar strands were also examined using live cell imaging. The possible importance of mitochondrial permeability transition pore (PTP) formation during PCD was indirectly examined via in vivo cyclosporine A (CsA) treatment. This treatment resulted in lace plant leaves with a significantly lower number of perforations compared to controls, and that displayed mitochondrial dynamics similar to that of non-PCD cells.'],\n",
       " 'labels': ['BACKGROUND', 'RESULTS'],\n",
       " 'meshes': ['Alismataceae',\n",
       "  'Apoptosis',\n",
       "  'Cell Differentiation',\n",
       "  'Mitochondria',\n",
       "  'Plant Leaves'],\n",
       " 'reasoning_required_pred': ['y', 'e', 's'],\n",
       " 'reasoning_free_pred': ['y', 'e', 's']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_dataset[\"train\"][0][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = semantic_search(test_question, embedding_model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance we can see that, with our sample question we are able to find the answer context in the top 5 context, we a evaluation need to be performed on the whole dataset to check how our retrieval system is working. \n",
    "\n",
    "Nevertheless, let continue with our work and perform the response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0, len(unlabeled_dataset[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37027"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_question = unlabeled_dataset[\"train\"][random_index][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does a novel penalized likelihood reconstruction of 18F-FDG PET-CT improve signal-to-background in colorectal liver metastases?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_retrieved_contexts = semantic_search(random_question, embedding_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This BPL reconstruction algorithm improved SNR and SBR for colorectal liver '\n",
      " 'metastases detected by 18F-FDG-PET/CT, increasing the lesion SUVmax without '\n",
      " 'increasing background liver SUV or image noise. This may improve the '\n",
      " 'detection of FDG-avid focal liver lesions and the diagnostic performance of '\n",
      " 'clinical 18F-FDG-PET/CT in this setting, with the largest impact for small '\n",
      " 'foci.')\n"
     ]
    }
   ],
   "source": [
    "random_answer = unlabeled_dataset[\"train\"][random_index][\"long_answer\"]\n",
    "pprint(random_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_gold_contexts = unlabeled_dataset[\"train\"][random_index][\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iterative reconstruction algorithms are widely used to reconstruct positron emission tomography computerised tomography (PET/CT) data. Lesion detection in the liver by 18F-fluorodeoxyglucose PET/CT (18F-FDG-PET/CT) is hindered by 18F-FDG uptake in background liver parenchyma. The aim of this study was to compare semi-quantitative parameters of histologically-proven colorectal liver metastases detected by 18F-FDG-PET/CT using data based on a Bayesian penalised likelihood (BPL) reconstruction, with data based on a conventional time-of-flight (ToF) ordered subsets expectation maximisation (OSEM) reconstruction.',\n",
       " \"A BPL reconstruction algorithm was used to retrospectively reconstruct sinogram PET data. This data was compared with OSEM reconstructions. A volume of interest was placed within normal background liver parenchyma. Lesions were segmented using automated thresholding. Lesion maximum standardised uptake value (SUVmax), standard deviation of background liver parenchyma SUV, signal-to-background ratio (SBR), and signal-to-noise ratio (SNR) were collated. Data was analysed using paired Student's t-tests and the Pearson correlation.\",\n",
       " 'Forty-two liver metastases from twenty-four patients were included in the analysis. The average lesion SUVmax increased from 8.8 to 11.6 (p<0.001) after application of the BPL algorithm, with no significant difference in background noise. SBR increased from 4.0 to 4.9 (p<0.001) and SNR increased from 10.6 to 13.1 (p<0.001) using BPL. There was a statistically significant negative correlation between lesion size and the percentage increase in lesion SUVmax (p=0.03).']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_gold_contexts[\"contexts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Iterative reconstruction algorithms are widely used to reconstruct positron '\n",
      " 'emission tomography computerised tomography (PET/CT) data. Lesion detection '\n",
      " 'in the liver by 18F-fluorodeoxyglucose PET/CT (18F-FDG-PET/CT) is hindered '\n",
      " 'by 18F-FDG uptake in background liver parenchyma. The aim of this study was '\n",
      " 'to compare semi-quantitative parameters of histologically-proven colorectal '\n",
      " 'liver metastases detected by 18F-FDG-PET/CT using data based on a Bayesian '\n",
      " 'penalised likelihood (BPL) reconstruction, with data based on a conventional '\n",
      " 'time-of-flight (ToF) ordered subsets expectation maximisation (OSEM) '\n",
      " 'reconstruction.')\n",
      "********************\n",
      "('The aim of this study is to evaluate the quality of I-124 PET images with '\n",
      " 'and without prompt gamma compensation (PGC) by comparing the recovery '\n",
      " 'coefficients (RC), the signal to noise ratios (SNR) and the contrast to F-18 '\n",
      " 'and Ga-68. Furthermore, the influence of the PGC on the quantification and '\n",
      " 'image quality is evaluated.')\n",
      "********************\n",
      "('The current perception of using contrast-enhanced CT (CECT) for attenuation '\n",
      " 'correction (AC) is that of caution, as it might lead to erroneously elevated '\n",
      " '(18)F-FDG uptake on the PET scan. This study evaluates in vivo whether an '\n",
      " 'intravenous iodinated contrast agent produces a significant AC artifact in '\n",
      " 'the level of standardized uptake value (SUV) changes in PET/CT.')\n",
      "********************\n",
      "('Different thresholding methods were reviewed and compared to our PET-based '\n",
      " 'gross tumor volume data obtained from a cohort of 31 non-small-cell lung '\n",
      " 'carcinoma patients who had undergone preoperative PET/CT scans for staging. '\n",
      " 'The feasibility and limitations of FDG-based PET/CT data on target volume '\n",
      " 'delineation in radiotherapy planning have been demonstrated with frequently '\n",
      " 'used approaches for target outlining such as the qualitative visual method '\n",
      " 'and the fixed 15% or 40% of the maximal iso-uptake value threshold methods.')\n",
      "********************\n",
      "('To test the influence of media injection in PET/CT on the functional or '\n",
      " 'gross tumour volume measurement.')\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "for context in random_retrieved_contexts:\n",
    "    pprint(context.get(\"text\"))\n",
    "    print(\"**\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The response generation part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question answering system, we will use the language  model that have been trained on the pub med qa! The model is called BiomedGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at michiyasunaga/BioLinkBERT-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"michiyasunaga/BioLinkBERT-large\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"michiyasunaga/BioLinkBERT-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_context = \" \".join([context[\"text\"]\n",
    "                                for context in random_retrieved_contexts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iterative reconstruction algorithms are widely used to reconstruct positron emission tomography computerised tomography (PET/CT) data. Lesion detection in the liver by 18F-fluorodeoxyglucose PET/CT (18F-FDG-PET/CT) is hindered by 18F-FDG uptake in background liver parenchyma. The aim of this study was to compare semi-quantitative parameters of histologically-proven colorectal liver metastases detected by 18F-FDG-PET/CT using data based on a Bayesian penalised likelihood (BPL) reconstruction, with data based on a conventional time-of-flight (ToF) ordered subsets expectation maximisation (OSEM) reconstruction. The aim of this study is to evaluate the quality of I-124 PET images with and without prompt gamma compensation (PGC) by comparing the recovery coefficients (RC), the signal to noise ratios (SNR) and the contrast to F-18 and Ga-68. Furthermore, the influence of the PGC on the quantification and image quality is evaluated. The current perception of using contrast-enhanced CT (CECT) for attenuation correction (AC) is that of caution, as it might lead to erroneously elevated (18)F-FDG uptake on the PET scan. This study evaluates in vivo whether an intravenous iodinated contrast agent produces a significant AC artifact in the level of standardized uptake value (SUV) changes in PET/CT. Different thresholding methods were reviewed and compared to our PET-based gross tumor volume data obtained from a cohort of 31 non-small-cell lung carcinoma patients who had undergone preoperative PET/CT scans for staging. The feasibility and limitations of FDG-based PET/CT data on target volume delineation in radiotherapy planning have been demonstrated with frequently used approaches for target outlining such as the qualitative visual method and the fixed 15% or 40% of the maximal iso-uptake value threshold methods. To test the influence of media injection in PET/CT on the functional or gross tumour volume measurement.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(random_question, concatenated_context,  return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_start_index = outputs.start_logits.argmax()\n",
    "answers_end_index = outputs.end_logits.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer_tokens = input_ids[\"input_ids\"][0, answers_start_index:answers_end_index+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f - 18 and ga -'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predicted_answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do mitochondria play a role in remodelling lace plant leaves during programmed cell death?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Results depicted mitochondrial dynamics in vivo as PCD progresses within the lace plant, and highlight the correlation of this organelle with other organelles during developmental PCD. To the best of our knowledge, this is the first report of mitochondria and chloroplasts moving on transvacuolar strands to form a ring structure surrounding the nucleus during developmental PCD. Also, for the first time, we have shown the feasibility for the use of CsA in a whole plant system. Overall, our findings implicate the mitochondria as playing a critical and early role in developmentally regulated PCD in the lace plant.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_dataset[\"train\"][0][\"long_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure if the model is working, but I will come back here to check if the model was working.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'embedding'],\n",
       "    num_rows: 206613\n",
       "})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_dataset_with_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial with BioGPT\n",
    "\n",
    "Let us now try to generate the answer with the GPT model which is a generative model for question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/biogpt\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/biogpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = f\"question: {random_question} context: {concatenated_context}\"\n",
    "encoded_input = tokenizer([input],\n",
    "                          return_tensors='pt',\n",
    "                          max_length=1024,\n",
    "                          truncation=True)\n",
    "output = model.generate(input_ids=encoded_input.input_ids,\n",
    "                        attention_mask=encoded_input.attention_mask, \n",
    "                        max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 627])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question: Does a novel penalized likelihood reconstruction of 18F-FDG PET-CT improve signal-to-background in colorectal liver metastases? context: Iterative reconstruction algorithms are widely used to reconstruct positron emission tomography computerised tomography (PET/CT) data. Lesion detection in the liver by 18F-fluorodeoxyglucose PET/CT (18F-FDG-PET/CT) is hindered by 18F-FDG uptake in background liver parenchyma. The aim of this study was to compare semi-quantitative parameters of histologically-proven colorectal liver metastases detected by 18F-FDG-PET/CT using data based on a Bayesian penalised likelihood (BPL) reconstruction, with data based on a conventional time-of-flight (ToF) ordered subsets expectation maximisation (OSEM) reconstruction. The aim of this study is to evaluate the quality of I-124 PET images with and without prompt gamma compensation (PGC) by comparing the recovery coefficients (RC), the signal to noise ratios (SNR) and the contrast to F-18 and Ga-68. Furthermore, the influence of the PGC on the quantification and image quality is evaluated. The current perception of using contrast-enhanced CT (CECT) for attenuation correction (AC) is that of caution, as it might lead to erroneously elevated (18)F-FDG uptake on the PET scan. This study evaluates in vivo whether an intravenous iodinated contrast agent produces a significant AC artifact in the level of standardized uptake value (SUV) changes in PET/CT. Different thresholding methods were reviewed and compared to our PET-based gross tumor volume data obtained from a cohort of 31 non-small-cell lung carcinoma patients who had undergone preoperative PET/CT scans for staging. The feasibility and limitations of FDG-based PET/CT data on target volume delineation in radiotherapy planning have been demonstrated with frequently used approaches for target outlining such as the qualitative visual method and the fixed 15% or 40% of the maximal iso-uptake value threshold methods. To test the influence of media injection in PET/CT on the functional or gross tumour volume measurement.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = generated_text.replace(input, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('question: Does a novel penalized likelihood reconstruction of 18F-FDG PET-CT '\n",
      " 'improve signal-to-background in colorectal liver metastases? context: '\n",
      " 'Iterative reconstruction algorithms are widely used to reconstruct positron '\n",
      " 'emission tomography computerised tomography (PET / CT) data. Lesion '\n",
      " 'detection in the liver by 18F-fluorodeoxyglucose PET / CT (18F-FDG-PET / CT) '\n",
      " 'is hindered by 18F-FDG uptake in background liver parenchyma. The aim of '\n",
      " 'this study was to compare semi-quantitative parameters of '\n",
      " 'histologically-proven colorectal liver metastases detected by 18F-FDG-PET / '\n",
      " 'CT using data based on a Bayesian penalised likelihood (BPL) reconstruction, '\n",
      " 'with data based on a conventional time-of-flight (ToF) ordered subsets '\n",
      " 'expectation maximisation (OSEM) reconstruction. The aim of this study is to '\n",
      " 'evaluate the quality of I-124 PET images with and without prompt gamma '\n",
      " 'compensation (PGC) by comparing the recovery coefficients (RC), the signal '\n",
      " 'to noise ratios (SNR) and the contrast to F-18 and Ga-68. Furthermore, the '\n",
      " 'influence of the PGC on the quantification and image quality is evaluated. '\n",
      " 'The current perception of using contrast-enhanced CT (CECT) for attenuation '\n",
      " 'correction (AC) is that of caution, as it might lead to erroneously elevated '\n",
      " '(18) F-FDG uptake on the PET scan. This study evaluates in vivo whether an '\n",
      " 'intravenous iodinated contrast agent produces a significant AC artifact in '\n",
      " 'the level of standardized uptake value (SUV) changes in PET / CT. Different '\n",
      " 'thresholding methods were reviewed and compared to our PET-based gross tumor '\n",
      " 'volume data obtained from a cohort of 31 non-small-cell lung carcinoma '\n",
      " 'patients who had undergone preoperative PET / CT scans for staging. The '\n",
      " 'feasibility and limitations of FDG-based PET / CT data on target volume '\n",
      " 'delineation in radiotherapy planning have been demonstrated with frequently '\n",
      " 'used approaches for target outlining such as the qualitative visual method '\n",
      " 'and the fixed 15% or 40% of the maximal iso-uptake value threshold methods. '\n",
      " 'To test the influence of media injection in PET / CT on the functional or '\n",
      " 'gross tumour volume measurement. The study included 1 0 patients with '\n",
      " 'colorectal liver metastases. The patients underwent a PET / CT scan after '\n",
      " 'intravenous injection of 1 8F-FDG. The PET / CT data were reconstructed '\n",
      " 'using the BPL and the OSEM reconstruction algorithms. The PET images were '\n",
      " 'analysed using the PERCIST software. The RC, SNR and the contrast to F-18 '\n",
      " 'and Ga-68 were calculated. The mean RC of the BPL reconstruction was '\n",
      " 'significantly higher than that of the OSEM reconstruction (p < 0. 0 0 1). '\n",
      " 'The SNR of the BPL reconstruction was significantly higher than that of the '\n",
      " 'OSEM reconstruction (p < 0. 0 0 1). The contrast to F-18 and Ga-68 was '\n",
      " 'significantly higher in the BPL reconstruction than in the OSEM '\n",
      " 'reconstruction (p < 0. 0 0 1). The mean SUV of the BPL reconstruction was '\n",
      " 'significantly higher than that of the OSEM reconstruction (p < 0. 0 0 1). '\n",
      " 'The mean SUV')\n"
     ]
    }
   ],
   "source": [
    "pprint(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This BPL reconstruction algorithm improved SNR and SBR for colorectal liver '\n",
      " 'metastases detected by 18F-FDG-PET/CT, increasing the lesion SUVmax without '\n",
      " 'increasing background liver SUV or image noise. This may improve the '\n",
      " 'detection of FDG-avid focal liver lesions and the diagnostic performance of '\n",
      " 'clinical 18F-FDG-PET/CT in this setting, with the largest impact for small '\n",
      " 'foci.')\n"
     ]
    }
   ],
   "source": [
    "pprint(random_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Few conclusion for the first part, we can see that the quality of the answers depend widelly on  the quality of the retrieved paragraphs. As it stand now, we will deploy the project and expose it to users and we will later come back on the evaluation and it's improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also conclude that splitting the text in shorter paragraphs have impacted the quality of the retrieved answers, we will need to find  a better way to deal with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few resources to consider: \n",
    "- https://www.reddit.com/r/LocalLLaMA/comments/15mq1ri/what_are_the_text_chunkingsplitting_and_embedding/\n",
    "- https://www.reddit.com/r/LangChain/comments/16m73j4/how_to_optimize_text_chunking_for_improved/\n",
    "- https://towardsdatascience.com/how-to-chunk-text-data-a-comparative-analysis-3858c4a0997a\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can deploy the model in production but we will get back to it to improve the quality of embeddings. \n",
    "\n",
    "And we will use the gpt model to generate the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
