{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Retrieval Augmented Generation (RAG) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will describe the whole process to build the RAG model using open source language.\n",
    "\n",
    "We will start by describing the high level overview of the system and then we will implement each component and set them up for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rag system highlevel](./images/RAG-high-level.jpeg)\n",
    "\n",
    "Rag High level([source:](https://blog.griddynamics.com/retrieval-augmented-generation-llm/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RAG system is a Information Retrieval and Question Answering system that uses Natural Language Processing (Or Generative AI for those who cares about buzz words), to answers users question using a knowledge base.\n",
    "The main benefits of a RAG system is the fact that you can use a personal knowledge base to answer your question, this limit hallucination in the system and more importanly helps the system to answers the question using a knowledge base from a specific domain. [Add More information about RAG systems here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the RAG System works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A canonical RAG Pipeline is build with the components illustrated in the figure below.\n",
    "![RAG system](./images/RAG-process-flow-scheme.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those 9 steps in the above figure can be group in 3 major steps.\n",
    "\n",
    "The knowledge encoding steps, the Retrieval Step and Generation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The knowledge Encoding\n",
    "\n",
    "We start with a corpus of our documents which can be a bunch of pdf document contains information about the question, or just internal website with the documentation. We split the document into manageable chunk which can be paragraphs in the documents and learn the embeddings vectors of those documents and save them in a vector database.\n",
    "That part can be summarize with the steps 1, 2, 3, and 4 in the picture {}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval \n",
    "\n",
    "This step retrieve the document similar to question from a document database. Given a question, we encode it and learn it embeddings and then we query the vector database using a similarity search approach to retrieve relevant context given a document. This part is done in the step 5, 6 in the picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation step\n",
    "\n",
    "In this step we take the question the context retrieve and feed that into the language model to generate the answer to the question given the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enough talking let us build the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retrieval system has 3 main components, the language model, the apis and the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esp.py/Projects/Personal/end-to-end-rag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_id = 'michiyasunaga/BioLinkBERT-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cache = Path().cwd().joinpath(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/esp.py/Projects/Personal/end-to-end-rag/models/michiyasunaga_BioLinkBERT-large. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "sentence_transformer = SentenceTransformer(embedding_model_id, cache_folder=model_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.retriever.embedding_model import SBertOnnxConfig, CustomEmbeddingBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(embedding_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedding_path = model_cache.joinpath(embedding_model_id.replace(\"/\", \"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/esp.py/Projects/Personal/end-to-end-rag/models/michiyasunaga_BioLinkBERT-large')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embedding_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = CustomEmbeddingBertModel.from_pretrained(bert_embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedding_onnx_path = bert_embedding_path.parent.joinpath(\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embedding_onnx_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model_config =SBertOnnxConfig.from_model_config(base_model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.onnx import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = f\"question: Is cytokeratin immunoreactivity useful in the diagnosis of short-segment Barrett's oesophagus in Korea? context: Cytokeratin 7/20 staining has been reported to be helpful in diagnosing Barrett's oesophagus and gastric intestinal metaplasia. However, this is still a matter of some controversy. To determine the diagnostic usefulness of cytokeratin 7/20 immunostaining for short-segment Barrett's oesophagus in Korea. In patients with Barrett's oesophagus, diagnosed endoscopically, at least two biopsy specimens were taken from just below the squamocolumnar junction. If goblet cells were found histologically with alcian blue staining, cytokeratin 7/20 immunohistochemical stains were performed. Intestinal metaplasia at the cardia was diagnosed whenever biopsy specimens taken from within 2 cm below the oesophagogastric junction revealed intestinal metaplasia. Barrett's cytokeratin 7/20 pattern was defined as cytokeratin 20 positivity in only the superficial gland, combined with cytokeratin 7 positivity in both the superficial and deep glands. Barrett's cytokeratin 7/20 pattern was observed in 28 out of 36 cases (77.8%) with short-segment Barrett's oesophagus, 11 out of 28 cases (39.3%) with intestinal metaplasia at the cardia, and nine out of 61 cases (14.8%) with gastric intestinal metaplasia. The sensitivity and specificity of Barrett's cytokeratin 7/20 pattern were 77.8 and 77.5%, respectively. answer: Barrett's cytokeratin 7/20 pattern can be a useful marker for the diagnosis of short-segment Barrett's oesophagus, although the false positive or false negative rate is approximately 25%.\"\n",
    "encoded_input = tokenizer([test_input],\n",
    "                          return_tensors='pt',\n",
    "                          max_length=512,\n",
    "                          truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = encoded_input.pop(\"token_type_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = base_model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model_embeddings = model_output.last_hidden_state.detach().numpy().reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "learned_embeddings = sentence_transformer.encode(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_array_almost_equal(custom_model_embeddings, learned_embeddings, decimal=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.onnx import export as torch_onnx_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esp.py/Projects/Personal/end-to-end-rag/.venv/lib/python3.10/site-packages/torch/onnx/utils.py:2095: UserWarning: Provided key last_hidden_state for dynamic axes is not a valid input/output name\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch_onnx_export(\n",
    "    base_model,\n",
    "    tuple(encoded_input.values()),\n",
    "    f=bert_embedding_onnx_path.joinpath('bio-bert-embedder.onnx'),\n",
    "    input_names=['input_ids', 'attention_mask'],\n",
    "    dynamic_axes={'input_ids': {0: 'batch_size', 1: 'sequence'},\n",
    "                  'attention_mask': {0: 'batch_size', 1: 'sequence'},\n",
    "                  'last_hidden_state': {0: 'batch_size', 1: 'sequence'}},\n",
    "    do_constant_folding=True,\n",
    "    opset_version=13,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.config.save_pretrained(bert_embedding_onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Comparison\n",
    "\n",
    "Let us now compare the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The ONNX file bio-bert-embedder.onnx is not a regular name used in optimum.onnxruntime, the ORTModel might not behave as expected.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_embedding_path.__str__( ))\n",
    "onnx_model = ORTModelForFeatureExtraction.from_pretrained(\n",
    "    bert_embedding_onnx_path)\n",
    "inputs_2 = tokenizer([sentences[0], sentences[1]],\n",
    "                     padding=\"longest\", return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_2.pop(\"token_type_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,  1805,  1744,  1683,  6239, 21011,     3],\n",
       "        [    2,  2562, 21011,  1744, 10215,     3,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_inputs = {\n",
    "    \"input_ids\": inputs_2.get(\"input_ids\").numpy(),\n",
    "    \"attention_mask\": inputs_2.get(\"attention_mask\").numpy(),\n",
    "}\n",
    "output_two = onnx_model.model.run(None, onnx_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_embeddings = output_two[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_embeddings = sentence_transformer.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_transformer_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31763083,  0.4523321 ,  0.50023586, ...,  0.13559678,\n",
       "       -0.1584263 , -0.04599122], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.31763083,  0.4523321 ,  0.50023586, ...,  0.13559678,\n",
       "         -0.1584263 , -0.04599122],\n",
       "        [ 0.02632874,  0.01244779, -0.08892691, ...,  0.13396056,\n",
       "          0.11261779,  0.08904688]], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are some weird behaviour but those are not expected in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Model to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOdel output successufly build as ONNX server, next step is to try it for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tritonclient.http as httpclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code in command line:\n",
    "\n",
    "```\n",
    " docker run --rm -p 8000:8000 -p 8001:8001 -p 8002:8002  --shm-size 128M -v ${PWD}/models_repository/retrieval:/models  espymur/triton-onnx:dev tritonserver --model-repository=/models\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = httpclient.InferenceServerClient(url=\"127.0.0.1:60815\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = httpclient.InferInput('TEXT', shape=[-1], datatype='BYTES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = httpclient.InferRequestedOutput('sequences_text', binary_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"what cause covid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tritonclient.http._infer_input.InferInput at 0x131182680>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_input_data = np.asarray([sentences], dtype=object)\n",
    "\n",
    "text = httpclient.InferInput('TEXT', [1], \"BYTES\")\n",
    "text.set_data_from_numpy(np_input_data.reshape([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "InferenceServerException",
     "evalue": "[400] unexpected inference output 'sequences_text' for model 'ensemble_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInferenceServerException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mensemble_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Personal/end-to-end-rag/.venv/lib/python3.10/site-packages/tritonclient/http/_client.py:1479\u001b[0m, in \u001b[0;36mInferenceServerClient.infer\u001b[0;34m(self, model_name, inputs, model_version, outputs, request_id, sequence_id, sequence_start, sequence_end, priority, timeout, headers, query_params, request_compression_algorithm, response_compression_algorithm, parameters)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     request_uri \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv2/models/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/infer\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(quote(model_name))\n\u001b[1;32m   1473\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1474\u001b[0m     request_uri\u001b[38;5;241m=\u001b[39mrequest_uri,\n\u001b[1;32m   1475\u001b[0m     request_body\u001b[38;5;241m=\u001b[39mrequest_body,\n\u001b[1;32m   1476\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1477\u001b[0m     query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m   1478\u001b[0m )\n\u001b[0;32m-> 1479\u001b[0m \u001b[43m_raise_if_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m InferResult(response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbose)\n",
      "File \u001b[0;32m~/Projects/Personal/end-to-end-rag/.venv/lib/python3.10/site-packages/tritonclient/http/_utils.py:69\u001b[0m, in \u001b[0;36m_raise_if_error\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m     67\u001b[0m error \u001b[38;5;241m=\u001b[39m _get_error(response)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mInferenceServerException\u001b[0m: [400] unexpected inference output 'sequences_text' for model 'ensemble_model'"
     ]
    }
   ],
   "source": [
    "results = client.infer(model_name=\"ensemble_model\", inputs=[text], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_output = results.as_numpy('sequences_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array('what cause covid-19.]? context: The novel coronavirus, severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), which causes coronavirus disease 2019 (Covid-19), has rapidly spread throughout the world leading to hundreds of deaths. The prevalence of antibodies against SARS-CoV-2 in the general population is unknown. To determine the prevalence of anti-SARS-CoV-2 antibodies in the general population in Buenos Aires, Argentina. We performed a cross-sectional study on a representative sample of the general population aged 18 years or older from the province of Buenos Aires, Argentina using an enzyme-linked immunosorbent assay (ELISA) to detect anti-SARS-CoV-2 antibodies. The overall prevalence of anti-SARS-CoV-2 antibodies was 25% (95% confidence interval [95% CI], 22% -31%). The prevalence was higher in women (34%) than in men (19%) (p = 0.002). The age-adjusted prevalence was higher in women (33%) than in men (19%) (p = 0.005). The highest prevalence was found in individuals aged 21 to 30 years (44%), followed by those aged 31 to 40 years (29%) and those aged 51 to 60 years (19%) (p < 0.001). <unk><unk><unk><unk><unk><unk><unk><unk><unk>the answer to the question given the context is yes.',\n",
      "      dtype=object)\n"
     ]
    }
   ],
   "source": [
    "pprint(inference_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding model is working as expected. Let us write the code for the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
