{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fails experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = Path.cwd().joinpath(\"datasets\", \"today_news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_news = current_directory.joinpath(\"2024-10-15-news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv(today_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path.cwd().joinpath(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_id = \"dunzhang/stella_en_400M_v5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_path = model_path.joinpath(embedding_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer_kwargs = {\"model_name_or_path\": embedding_model_path.__str__(),\n",
    "                      \"trust_remote_code\": True,\n",
    "                      \"device\": \"cpu\",\n",
    "                      \"config_kwargs\": {\"use_memory_efficient_attention\": False,\n",
    "                                        \"unpad_inputs\": False},\n",
    "                      \"cache_folder\": model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_model = SentenceTransformer(\n",
    "    **transformer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embeddings = sentence_transformer_model.encode(news_df[\"title\"].values.tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_estimator(X):\n",
    "    K_mean_estimators = [\n",
    "        (f\"KMeans_{i}\", KMeans(n_clusters=i, random_state=42)) for i in range(2, X.shape[0])]\n",
    "    pca_estimator = PCA(n_components=X.shape[0])\n",
    "\n",
    "    best_estimator = None\n",
    "    best_metric = float(\"-inf\")\n",
    "    intertias  = []\n",
    "    for estimator_name, estimator in K_mean_estimators:\n",
    "        transformed_X = pca_estimator.fit_transform(X)\n",
    "        estimator.fit(transformed_X)\n",
    "        labels = estimator.labels_\n",
    "        score = silhouette_score(\n",
    "            transformed_X, labels)\n",
    "        if score > best_metric:\n",
    "            best_metric = score\n",
    "            best_estimator = estimator\n",
    "        intertias.append(estimator.inertia_)\n",
    "    return best_estimator, intertias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator, intertias = find_best_estimator(title_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(2, title_embeddings.shape[0]), intertias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the shiloulette score does never reach 1, the maximum I can get is 0.12, which indicate that all my cluster a overlaping and k mean does not perform very well here. Let me a hierachical clustering approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_silhouette_values = silhouette_samples(title_embeddings, best_estimator.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDBSCan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered = hdbscan.HDBSCAN(min_cluster_size=6, min_samples=3, cluster_selection_epsilon=0.75).fit(title_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiearchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "connectivity = kneighbors_graph(title_embeddings, n_neighbors=10, include_self=False, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = sentence_transformer_model.similarity(title_embeddings, title_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_distance = 1 - similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compute structured hierarchical clustering...\")\n",
    "st = time.time()\n",
    "agglomerative = AgglomerativeClustering(connectivity=connectivity,\n",
    "                                        linkage=\"complete\",\n",
    "                                        metric=\"cosine\",\n",
    "                                        n_clusters=6)\n",
    "\n",
    "agglomerative.fit(title_embeddings)\n",
    "mean_shilouette_score = silhouette_score(title_embeddings, agglomerative.labels_)\n",
    "elapsed_time = time.time() - st\n",
    "label = agglomerative.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df[\"labels_agglomerative\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_embeddings(dataframe, embeddings, index, label_column=\"labels\"):\n",
    "    \"\"\" take an matrix of embeddings, and the labels.\n",
    "    for each label compute the cosine similarity of document with that label.\n",
    "    \"\"\"\n",
    "    document_in_index = dataframe.query(f\"{label_column} == {index}\")\n",
    "    with pd.option_context('display.max_colwidth', None):\n",
    "        display(document_in_index.title)\n",
    "    document_index = document_in_index.index\n",
    "    vectors = embeddings[document_index]\n",
    "    return sentence_transformer_model.similarity(vectors,  vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_embeddings(news_df, title_embeddings, 0, \"labels_agglomerative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.query(\"labels_agglomerative == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca_embeddings = pca.fit_transform(title_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax1.set_position([0, 0, 0.95, 1])\n",
    "for l in np.unique(label):\n",
    "    ax1.scatter(\n",
    "        pca_embeddings[label == l, 0],\n",
    "        pca_embeddings[label == l, 1],\n",
    "        color=plt.cm.jet(float(l) / np.max(label + 1)),\n",
    "        s=20,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "_ = fig1.suptitle(\n",
    "    f\"Without connectivity constraints (time {elapsed_time:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
